{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import imageio\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "from IPython.display import Image, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Configuration:\n",
    "    COLOR_CHANNEL = 3\n",
    "    CONTENT_IMAGE = 'images/content_image.jpg'\n",
    "    IMAGE_HEIGHT= imageio.imread(CONTENT_IMAGE).shape[0]\n",
    "    IMAGE_WIDTH= imageio.imread(CONTENT_IMAGE).shape[1]\n",
    "    STYLE_IMAGE = 'images/style_image.jpg'\n",
    "    OUPUT = 'images/'\n",
    "    NOISE_RATIO = 0.6\n",
    "    ALPHA = 100\n",
    "    BETA = 5\n",
    "    PATH_VGG_MODEL = 'pretrained_model/imagenet-vgg-verydeep-19.mat'\n",
    "    MEAN = np.array([123.68,116.779, 103.939]).reshape((1,1,1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vgg(path_location):\n",
    "    vgg = scipy.io.loadmat(path_location)\n",
    "    vgg_layers = vgg['layers']\n",
    "    \n",
    "    def _weights(layer,expected_layer_name):\n",
    "        weight_basis = vgg_layers[0][layer][0][0][2]\n",
    "        weights = weight_basis[0][0]\n",
    "        basises = weight_basis[0][1]\n",
    "        layer_name = vgg_layers[0][layer][0][0][0][0]\n",
    "        return weights,basises\n",
    "    \n",
    "    def _relu(conv_layer):\n",
    "        return tf.nn.relu(conv_layer)\n",
    "    \n",
    "    def _conv(previous_layer,layer,layer_name):\n",
    "        wght,bsis = _weights(layer,layer_name)\n",
    "        wght = tf.constant(wght)\n",
    "        bsis_reshape = np.reshape(bsis,(bsis.size))  \n",
    "        bsis = tf.constant(bsis_reshape)\n",
    "        return tf.nn.conv2d(previous_layer,filter=wght,strides=[1,1,1,1],padding='SAME')+ bsis\n",
    "    \n",
    "    def _conv_relu(previous_layer,layer,layer_name):\n",
    "        return _relu(_conv(previous_layer,layer,layer_name))\n",
    "    \n",
    "    def _average_pooling(previous_layer):\n",
    "        return tf.nn.avg_pool(previous_layer,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "    \n",
    "    # graph model to be implemented\n",
    "    graph={}\n",
    "    graph['input']   = tf.Variable(np.zeros((1, Configuration.IMAGE_HEIGHT, Configuration.IMAGE_WIDTH, Configuration.COLOR_CHANNEL)), dtype = 'float32')\n",
    "    graph['conv1_1']  = _conv_relu(graph['input'], 0, 'conv1_1')\n",
    "    graph['conv1_2']  = _conv_relu(graph['conv1_1'], 2, 'conv1_2')\n",
    "    graph['avgpool1'] = _average_pooling(graph['conv1_2'])\n",
    "    graph['conv2_1']  = _conv_relu(graph['avgpool1'], 5, 'conv2_1')\n",
    "    graph['conv2_2']  = _conv_relu(graph['conv2_1'], 7, 'conv2_2')\n",
    "    graph['avgpool2'] = _average_pooling(graph['conv2_2'])\n",
    "    graph['conv3_1']  = _conv_relu(graph['avgpool2'], 10, 'conv3_1')\n",
    "    graph['conv3_2']  = _conv_relu(graph['conv3_1'], 12, 'conv3_2')\n",
    "    graph['conv3_3']  = _conv_relu(graph['conv3_2'], 14, 'conv3_3')\n",
    "    graph['conv3_4']  = _conv_relu(graph['conv3_3'], 16, 'conv3_4')\n",
    "    graph['avgpool3'] = _average_pooling(graph['conv3_4'])\n",
    "    graph['conv4_1']  = _conv_relu(graph['avgpool3'], 19, 'conv4_1')\n",
    "    graph['conv4_2']  = _conv_relu(graph['conv4_1'], 21, 'conv4_2')\n",
    "    graph['conv4_3']  = _conv_relu(graph['conv4_2'], 23, 'conv4_3')\n",
    "    graph['conv4_4']  = _conv_relu(graph['conv4_3'], 25, 'conv4_4')\n",
    "    graph['avgpool4'] = _average_pooling(graph['conv4_4'])\n",
    "    graph['conv5_1']  = _conv_relu(graph['avgpool4'], 28, 'conv5_1')\n",
    "    graph['conv5_2']  = _conv_relu(graph['conv5_1'], 30, 'conv5_2')\n",
    "    graph['conv5_3']  = _conv_relu(graph['conv5_2'], 32, 'conv5_3')\n",
    "    graph['conv5_4']  = _conv_relu(graph['conv5_3'], 34, 'conv5_4')\n",
    "    graph['avgpool5'] = _average_pooling(graph['conv5_4'])\n",
    "    \n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_white_noise_content_image(content_image):\n",
    "    white_noise_image = np.random.uniform(-20,20,(1,Configuration.IMAGE_HEIGHT,Configuration.IMAGE_WIDTH,Configuration.COLOR_CHANNEL)).astype('float32')\n",
    "    input_content_image = white_noise_image + content_image\n",
    "    return input_content_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reshape_normalize(img):\n",
    "    img = np.reshape(img,((1,) + img.shape))\n",
    "    img = img - Configuration.MEAN\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_image(path_location,output_image):\n",
    "    output_image = output_image.astype('float32') + Configuration.MEAN\n",
    "    output_image = np.clip(output_image[0],0,255).astype('uint8')\n",
    "    imageio.imwrite(path_location,output_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_c_image = imageio.imread(Configuration.CONTENT_IMAGE)\n",
    "input_content_image = _reshape_normalize(input_c_image)\n",
    "input_s_image = imageio.imread(Configuration.STYLE_IMAGE)\n",
    "input_style_image = _reshape_normalize(input_s_image)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_content_loss(activation_content_image, activation_generate_image):\n",
    "    m, N,M1,M2 = activation_generate_image.get_shape().as_list()\n",
    "    activation_content_image_reshape = tf.transpose(tf.reshape(activation_content_image,[N*M1,M2]))\n",
    "    activation_generate_image_reshape = tf.transpose(tf.reshape(activation_generate_image,[N*M1,M2]))\n",
    "    mean_square_distance = tf.reduce_sum(tf.square(tf.subtract(activation_content_image_reshape,activation_generate_image_reshape)))\n",
    "    content_loss = (1/(4*N*M1*M2))* mean_square_distance\n",
    "    return content_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gram_matrix(A):\n",
    "    return tf.matmul(A,tf.transpose(A))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_layer_style_loss(activation_style_image,activation_generate_image):\n",
    "    m,N,M1,M2 = activation_generate_image.get_shape().as_list()\n",
    "    activation_style_image = tf.transpose(tf.reshape(activation_style_image,[N*M1,M2]))\n",
    "    activation_generate_image = tf.transpose(tf.reshape(activation_generate_image,[N*M1,M2]))\n",
    "    gram_matrix_style_image = _gram_matrix(activation_style_image) \n",
    "    gram_matrix_generate_image = _gram_matrix(activation_generate_image)\n",
    "    mean_square_distance = tf.reduce_sum(tf.square(tf.subtract( gram_matrix_generate_image,gram_matrix_style_image)))\n",
    "    layer_style_loss = (1/(4*M2*M2*(N*M1)*(N*M1))) * mean_square_distance\n",
    "    return layer_style_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "STYLE_IMAGE_LAYER = [('conv1_1',0.2),\n",
    "                     ('conv2_1',0.2),\n",
    "                     ('conv3_1',0.2),\n",
    "                     ('conv4_1',0.2),\n",
    "                     ('conv5_1',0.2)\n",
    "                    ]\n",
    "\n",
    "def _compute_style_loss(model,STYLE_IMAGE_LAYER):\n",
    "    style_loss = 0\n",
    "    for layer_name, coeff in STYLE_IMAGE_LAYER:\n",
    "        ouput_tensor = model[layer_name]\n",
    "        hidden_activation_layer_style = sess.run(output_tensor)\n",
    "        hidden_activation_layer_generate = output_tensor\n",
    "        style_loss = _compute_layer_style_loss(hidden_activation_layer_style,hidden_activation_layer_generate)\n",
    "    return style_loss\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _total_loss(content_loss,style_loss):\n",
    "    total_loss = Configuration.ALPHA*content_loss + Configuration.BETA*style_loss\n",
    "    return content_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "content_image = _generate_white_noise_content_image(input_content_image)\n",
    "model = load_vgg(Configuration.PATH_VGG_MODEL)\n",
    "sess.run(model['input'].assign(input_content_image))\n",
    "output_tensor = model['conv4_2']\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_activation_content = sess.run(output_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_activation_generate = output_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_loss = _compute_content_loss(hidden_layer_activation_content,hidden_layer_activation_generate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_loss = _compute_style_loss(model,STYLE_IMAGE_LAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_loss = _total_loss(content_loss,style_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#setting the training parameters\n",
    "optimizer = tf.train.AdamOptimizer(2.0)\n",
    "training_step = optimizer.minimize(total_loss)\n",
    "path_generate_image = 'images/'+'generate_image'+'.jpg'\n",
    "iteration = 1\n",
    "def _model_nn(sess,input_img,path_generate_img,iteration):\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(model['input'].assign(input_img))\n",
    "    \n",
    "    for i in range(iteration):\n",
    "        sess.run(training_step)\n",
    "        generate_image = sess.run(model['input'])\n",
    "    _save_image(path_generate_image,generate_image)\n",
    "    return generate_image\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[  47.371773 ,   43.645855 ,  -43.62001  ],\n",
       "         [  64.11642  ,   55.25156  ,  -65.00101  ],\n",
       "         [  75.2983   ,   44.514256 ,  -42.622356 ],\n",
       "         ...,\n",
       "         [ -70.50369  ,  -85.77461  ,  -79.5834   ],\n",
       "         [ -67.65833  , -108.33963  , -100.36853  ],\n",
       "         [ -75.73836  ,  -96.07812  ,  -92.920715 ]],\n",
       "\n",
       "        [[  53.685734 ,   36.000416 ,  -50.69269  ],\n",
       "         [  63.475937 ,   27.222778 ,  -39.411804 ],\n",
       "         [  72.05054  ,   28.707844 ,  -46.53804  ],\n",
       "         ...,\n",
       "         [ -85.61189  ,  -75.35185  ,  -92.856674 ],\n",
       "         [ -58.680775 ,  -72.06052  ,  -86.102104 ],\n",
       "         [ -97.02571  ,  -92.71491  ,  -88.17859  ]],\n",
       "\n",
       "        [[  56.17624  ,   55.62645  ,  -39.18123  ],\n",
       "         [  73.60198  ,   49.726997 ,  -27.178413 ],\n",
       "         [  55.607285 ,   57.697075 ,  -21.744074 ],\n",
       "         ...,\n",
       "         [ -41.100037 ,  -54.172623 ,  -61.821728 ],\n",
       "         [ -62.107117 ,  -68.87981  ,  -44.67928  ],\n",
       "         [ -61.88029  ,  -70.89897  ,  -90.10546  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  81.00637  ,   17.24878  ,  -91.32694  ],\n",
       "         [  64.47713  ,   24.612051 ,  -63.273476 ],\n",
       "         [  51.641308 ,   15.7739725,  -69.29461  ],\n",
       "         ...,\n",
       "         [  72.42286  ,   84.077225 ,  -69.82478  ],\n",
       "         [  68.01519  ,   51.422462 ,  -56.246307 ],\n",
       "         [  93.55952  ,   76.795876 ,  -51.050667 ]],\n",
       "\n",
       "        [[  71.88173  ,   59.320324 ,  -34.42623  ],\n",
       "         [  70.73532  ,   42.082546 ,  -41.636627 ],\n",
       "         [  52.426872 ,   25.396769 ,  -58.97329  ],\n",
       "         ...,\n",
       "         [  57.347076 ,   57.95628  ,  -71.81798  ],\n",
       "         [  90.280594 ,   87.684525 ,  -54.231194 ],\n",
       "         [  63.840343 ,   54.33946  ,  -22.383915 ]],\n",
       "\n",
       "        [[  75.60252  ,   55.80131  ,  -56.242073 ],\n",
       "         [  85.90898  ,   11.131729 ,  -77.89854  ],\n",
       "         [  90.39123  ,   51.31724  ,  -61.86287  ],\n",
       "         ...,\n",
       "         [  79.34912  ,   70.673965 ,  -65.351776 ],\n",
       "         [  85.049095 ,   52.421997 ,  -70.53133  ],\n",
       "         [  79.93631  ,   61.502125 ,  -33.704426 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_model_nn(sess,content_image,path_generate_image,iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
